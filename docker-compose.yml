version: '3'

# The environment variable "TAG" is used throughout this file to
# specify the version of the images to run. The default is set in the
# '.env' file in this folder. It can be overridden with any normal
# technique for setting environment variables, for example:
#
#   TAG=7.8.0-beta1 docker-compose up
#
# REF: https://docs.docker.com/compose/compose-file/#variable-substitution
#
# Also be sure to set the ELASTIC_VERSION variable. For released versions,
# ${TAG} and ${ELASTIC_VERSION} will be identical, but for pre-release
# versions, ${TAG} might contain an extra build identifier, like
# "7.8.0-beta1-3eab5b40", so a full invocation might look like:
#
#  ELASTIC_VERSION=7.8.0-beta1 TAG=7.8.0-beta1-3eab5b40 docker-compose up

services:
    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:${TAG:-7.8.0}
        container_name: elasticsearch
        restart: 'no'
        ulimits:
            memlock:
                soft: -1
                hard: -1
        network_mode: host
        volumes:
            # Need to create this on the local file system where Elasticsearch will store data.
            # For example...
            #   mkdir /var/lib/elasticsearch && chown -R 1000:1000 /var/lib/elasticsearch
            - /var/lib/es_data:/usr/share/elasticsearch/data
            - ./certs:/usr/share/elasticsearch/config/certs:ro
        environment:
            # JVM Heap size
            #   - this should be at least 2GB for simple testing, receiving only a few flows per second.
            #   - for production environments upto 31GB is recommended.
            ES_JAVA_OPTS: '-Xms8g -Xmx8g'
            ELASTIC_PASSWORD: pensando
            ELASTIFLOW_RESOLVE_IP2HOST: 'true'
            cluster.name: pensando.elastic
            node.name: elasticsearch-dmz.pensando.dev
            bootstrap.memory_lock: 'true'
            network.host: 0.0.0.0
            http.port: 9200
            discovery.type: 'single-node'
            indices.query.bool.max_clause_count: 8192
            search.max_buckets: 10000000
            # change the following to true if you don't want to be able to wildcard delete
            action.destructive_requires_name: 'false'
            http.cors.enabled: 'true'
            http.cors.allow-credentials: 'true'
            http.cors.allow-methods: 'OPTIONS,HEAD,GET,POST,PUT,DELETE'
            http.cors.allow-headers: 'Requested-With,Content-Type,Content-Length,Authorization,X-Requested-With'
            #http.cors.allow-origin: *
            # xpack.security.transport.ssl.enabled: 'true'
            # xpack.security.transport.ssl.verification_mode: 'none'
            # xpack.security.transport.ssl.key: '/usr/share/elasticsearch/config/certs/elasticsearch-dmz.pensando.dev.key.pem'
            # xpack.security.transport.ssl.certificate: '/usr/share/elasticsearch/config/certs/elasticsearch-dmz.pensando.dev.cert.pem'
            # xpack.security.transport.ssl.certificate_authorities: '/usr/share/elasticsearch/config/certs/ca-chain.cert.pem'
            # xpack.security.http.ssl.enabled: 'true'
            # xpack.security.http.ssl.verification_mode: 'none'
            # xpack.security.http.ssl.key: '/usr/share/elasticsearch/config/certs/elasticsearch-dmz.pensando.dev.key.pem'
            # xpack.security.http.ssl.certificate: '/usr/share/elasticsearch/config/certs/elasticsearch-dmz.pensando.dev.cert.pem'
            # xpack.security.http.ssl.certificate_authorities: '/usr/share/elasticsearch/config/certs/ca-chain.cert.pem'
            # xpack.security.enabled: 'true'

    kibana:
        image: docker.elastic.co/kibana/kibana:${TAG:-7.8.0}
        container_name: kibana
        restart: 'no'
        depends_on:
            - elasticsearch
        network_mode: host
        environment:
            SERVER_HOST: 0.0.0.0
            SERVER_PORT: 5601
            SERVER_MAXPAYLOADBYTES: 4194304
            ELASTICSEARCH_HOSTS: "http://${ELASTICSEARCH_HOST:-127.0.0.1}:9200"
            KIBANA_DEFAULTAPPID: "dashboard/653cf1e0-2fd2-11e7-99ed-49759aed30f5"
            LOGGING_DEST: stdout
            LOGGING_QUIET: 'false'

    elastiflow-logstash-oss:
        image: robcowart/elastiflow-logstash-oss:4.0.0-beta
        container_name: elastiflow-logstash-oss
        restart: 'no'
        depends_on:
            - elasticsearch
        network_mode: host
        environment:
            # JVM Heap size - this MUST be at least 3GB (4GB preferred)
            LS_JAVA_OPTS: '-Xms4g -Xmx4g'
            # ElastiFlow global configuration
            ELASTIFLOW_DEFAULT_APPID_SRCTYPE: "__UNKNOWN"
            ELASTIFLOW_RESOLVE_IP2HOST: "false"
            ELASTIFLOW_NAMESERVER: "${DNS_IP:-8.8.8.8}"
            ELASTIFLOW_NETFLOW_IPV4_PORT: 2055
            ELASTIFLOW_SFLOW_IPV4_PORT: 6343
            ELASTIFLOW_IPFIX_TCP_IPV4_PORT: 4739
            ELASTIFLOW_IPFIX_UDP_IPV4_PORT: 4739
            ELASTIFLOW_ES_HOST: "http://${ELASTICSEARCH_HOST:-127.0.0.1}:9200"